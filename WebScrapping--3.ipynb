{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3da4717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ca65cb",
   "metadata": {},
   "source": [
    "# 1. Write a python program which searches all the product under a particular product from www.amazon.in. Theproduct to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for\n",
    "guitars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4657178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"http://www.amazon.in/\")\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "enter=driver.find_element(By.XPATH,(\"\"\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\"\"\"))\n",
    "enter.send_keys(input('enter_item:'))\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043906d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,(\"\"\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\"\"\"))\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc6f7d6",
   "metadata": {},
   "source": [
    "# 2. In the above question, now scrape the following details of each product listed in first 3 pages of your searchresults and save it in a data frame and csv. In case if any product has less than 3 pages in search results thenscrape all the products available under that product name. Details to be scraped are: \"BrandName\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccd68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Url=[]\n",
    "start=0\n",
    "end=3\n",
    "\n",
    "for page in range(start,end):\n",
    "    url_tag=driver.find_elements(By.XPATH,'//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "    for i in url_tag:\n",
    "        Url.append(i.get_attribute('href'))\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')  \n",
    "    next_button.click()\n",
    "    time.sleep(5)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eabb9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "expected_delivery = []\n",
    "returns = []\n",
    "availability = []\n",
    "price=[]\n",
    "Brand=[]\n",
    "\n",
    "for url in Url:  \n",
    "    driver.get(url)\n",
    "    time.sleep(5)  \n",
    "        \n",
    "    try:\n",
    "        name_tag=driver.find_element(By.XPATH,'//span[@id=\"productTitle\"]')\n",
    "        name.append(name_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        name.append('_')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        expected_delivery_tag = driver.find_element(By.XPATH, '//DIV[@class=\"a-spacing-base\"][1]')\n",
    "        expected_delivery.append(expected_delivery_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        expected_delivery.append('_')\n",
    "        try:\n",
    "        return_tag = driver.find_element(By.XPATH, '//li[@class=\"a-carousel-card tw-scroll-carousel-element\"][1]//span')\n",
    "        returns.append(return_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        returns.append(\"_\")\n",
    "\n",
    "    try:\n",
    "        availability_tag = driver.find_element(By.XPATH, '//div[@id=\"availability\"]')\n",
    "        availability.append(availability_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        availability.append(\"_\")\n",
    "        \n",
    "    try:\n",
    "        price_tag=driver.find_element(By.XPATH,'//span[@class=\"a-price-whole\"][1]')\n",
    "        price.append(price_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        price.append('_')\n",
    "        \n",
    "    try:\n",
    "        Brand_tag = driver.find_element(By.XPATH,'//div[@class=\"a-section a-spacing-medium brand-snapshot-flex-row\"]//p')\n",
    "        Brand.append(Brand_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        Brand.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(name),len(expected_delivery),len(returns),len(availability),len(price),len(Brand),len(Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff6517",
   "metadata": {},
   "outputs": [],
   "source": [
    "Product=pd.DataFrame({'Brand name':Brand,'Name of the product':name,'Price':price,'Return/Exchange':returns,'Expected delivery':expected_delivery,'Availability':availability,'Product URL':Url})\n",
    "Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2b5b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save in csv file\n",
    "Product.to_csv('amazone_product.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945ee01c",
   "metadata": {},
   "source": [
    "# 3. Write a python program to access the search bar and search button on images.google.com and scrape 10images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5bf1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://images.google.com/')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd99d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/textarea')\n",
    "search.send_keys('fruits')\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e416d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,'//button[@class=\"Tg7LZd\"]')\n",
    "search_button.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca38b0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fruit_url=[]\n",
    "for i in range(len(Fruit_url)):\n",
    "    response = requests.get(Fruit_url[i])\n",
    "    if response.status_code == 200:\n",
    "        with open(r\"F:\\Image url\\image\" + str(i) + \".jpg\", 'wb') as file:\n",
    "            file.write(response.content)\n",
    "    else:\n",
    "        print(\"Failed to download image\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a1581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be87e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/c-wiz/c-wiz/div/div[3]/div[2]/div/div[1]/form/div[1]/div[2]/div/div[2]/input')\n",
    "search.send_keys('cars')\n",
    "time.sleep(1)\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/c-wiz/c-wiz/div/div[3]/div[2]/div/div[1]/form/div[1]/div[2]/button')\n",
    "search_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "cars_url=[]\n",
    "\n",
    "url_tag=driver.find_elements(By.XPATH,'//div[@class=\"fR600b islir\"]//img')\n",
    "for url in url_tag[0:10]:\n",
    "    cars_url.append(url.get_attribute('src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28974ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/c-wiz/c-wiz/div/div[3]/div[2]/div/div[1]/form/div[1]/div[2]/div/div[2]/input')\n",
    "search.send_keys('Machine_learning')\n",
    "time.sleep(1)\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/c-wiz/c-wiz/div/div[3]/div[2]/div/div[1]/form/div[1]/div[2]/button')\n",
    "search_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "machinelearning_url=[]\n",
    "\n",
    "url_tag=driver.find_elements(By.XPATH,'//div[@class=\"fR600b islir\"]//img')\n",
    "for url in url_tag[0:10]:\n",
    "    machinelearning_url.append(url.get_attribute('src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e681f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/c-wiz/c-wiz/div/div[3]/div[2]/div/div[1]/form/div[1]/div[2]/div/div[2]/input')\n",
    "search.send_keys('Guitar')\n",
    "time.sleep(1)\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/c-wiz/c-wiz/div/div[3]/div[2]/div/div[1]/form/div[1]/div[2]/button')\n",
    "search_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "Guitar_url=[]\n",
    "\n",
    "url_tag=driver.find_elements(By.XPATH,'//div[@class=\"fR600b islir\"]//img')\n",
    "for url in url_tag[0:10]:\n",
    "    Guitar_url.append(url.get_attribute('src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fabf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/c-wiz/c-wiz/div/div[3]/div[2]/div/div[1]/form/div[1]/div[2]/div/div[2]/input')\n",
    "search.send_keys('Cakes')\n",
    "time.sleep(1)\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/c-wiz/c-wiz/div/div[3]/div[2]/div/div[1]/form/div[1]/div[2]/button')\n",
    "search_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "cake_url=[]\n",
    "\n",
    "url_tag=driver.find_elements(By.XPATH,'//div[@class=\"fR600b islir\"]//img')\n",
    "for url in url_tag[0:10]:\n",
    "    cake_url.append(url.get_attribute('src'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613f7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fruits_url),len(cars_url),len(machinelearning_url),len(Guitar_url),len(cake_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873378d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_url=pd.DataFrame({'fruits':fruits_url,'cars':cars_url,'Machine Learning':machinelearning_url,'Guitar':Guitar_url,'Cakes':cake_url})\n",
    "images_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5096fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruits_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aba6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "machinelearning_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "Guitar_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cdc670",
   "metadata": {},
   "outputs": [],
   "source": [
    "cake_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00de9b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com\n",
    "and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand\n",
    "Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the\n",
    "details is missing then replace it by “- “. Save your results in a dataframe and CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef63a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('http://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd90feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input')\n",
    "search.send_keys(input('enter item to be searched'))\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb09931",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,'//button[@class=\"_2iLD__\"]')\n",
    "search_button.click()\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6505a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Url=[]\n",
    "\n",
    "url_tag=driver.find_elements(By.XPATH,'//a[@class=\"_1fQZEK\"]')\n",
    "for tag in url_tag:\n",
    "    Url.append(tag.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53cbea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "name=[]\n",
    "colour=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f760ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in Url:\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    try:\n",
    "        brand_tag=driver.find_element(By.XPATH,'//span[@class=\"B_NuCI\"]')\n",
    "        Brand.append(brand_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        Brand.append('_')\n",
    "        \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        name_tag=driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][1]/table/tbody/tr[3]/td[2]/ul/li')\n",
    "        name.append(name_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        name.append('_')    \n",
    "         try:\n",
    "        colour_tag=driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][1]/table/tbody/tr[4]/td[2]/ul/li')\n",
    "        colour.append(colour_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        colour.append('_')\n",
    "        \n",
    "    try:\n",
    "        price_tag=driver.find_element(By.XPATH,'//div[@class=\"_30jeq3 _16Jk6d\"]')\n",
    "        price.append(price_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        price.append('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b02c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brands=[i.split()[0] for i in Brand]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe32543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage=[]\n",
    "\n",
    "storage_tag=driver.find_elements(By.XPATH,'//div[@class=\"fMghEO\"]/ul/li[1]')\n",
    "for tag in storage_tag:\n",
    "    storage.append(tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0123d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAM=[i.split()[0] for i in storage]\n",
    "storage_ROM=[i.split()[4] for i in storage]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6ec205",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cameras=[]\n",
    "\n",
    "camera_tag=driver.find_elements(By.XPATH,'//div[@class=\"fMghEO\"]/ul/li[3]')\n",
    "for tag in camera_tag:\n",
    "    result=re.findall(r'\\b([^\\(|]+)\\|', tag.text)\n",
    "    Cameras.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9cf1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "secondarycamera=[]\n",
    "\n",
    "camera_tag=driver.find_elements(By.XPATH,'//div[@class=\"fMghEO\"]/ul/li[3]')\n",
    "for tag in camera_tag:\n",
    "    result=re.findall(r'\\|(.*)', tag.text)\n",
    "    secondarycamera.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "display=[]\n",
    "\n",
    "display_tag=driver.find_elements(By.XPATH,'//div[@class=\"fMghEO\"]/ul/li[2]')\n",
    "for tag in display_tag:\n",
    "    display.append(tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82afe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "battery=[]\n",
    "\n",
    "battery_tag=driver.find_elements(By.XPATH,'//div[@class=\"fMghEO\"]/ul/li[4]')\n",
    "for tag in battery_tag:\n",
    "    battery.append(tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ac4838",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Brands),len(name),len(colour),len(RAM),len(storage_ROM),len(Cameras),len(secondarycamera),len(display),len(battery),len(price),len(Url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a878304",
   "metadata": {},
   "outputs": [],
   "source": [
    "Smartphone=pd.DataFrame({'Brand Name':Brands,'Smartphone Name':name,'Colour':colour,'RAM (GB)':RAM,'Storage(ROM)(GB)':storage_ROM,'Primary Camera':Cameras,'Secondary Camera':secondarycamera,'Display Size':display,'Battery Capacity':battery,'Price':price,'Product URL':Url})\n",
    "Smartphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ca892",
   "metadata": {},
   "outputs": [],
   "source": [
    "Smartphone.to_csv('Flipkart_smartphone.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227abae2",
   "metadata": {},
   "source": [
    "# 5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233da012",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.google.com/maps/@13.0187264,77.5880704,12z?entry=ttu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d818aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div[8]/div[3]/div[1]/div[1]/div/div[2]/form/input')\n",
    "search.send_keys(input('Enter city name to be searched'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c2894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,'//button[@class=\"mL3xi\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_string=driver.current_url\n",
    "print('URL extracted:',url_string)\n",
    "lat_lang=re.findall(r'@(.*)data',url_string)\n",
    "lat_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec588f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lat_lang:\n",
    "    result=i.split(',')\n",
    "result   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea191cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Latitude=result[0]\n",
    "Longitude=result[1]\n",
    "print('Latitude:',latitude)\n",
    "print('Longitude:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cbd96b",
   "metadata": {},
   "source": [
    "# 6. Write a program to scrap all the available details of best gaming laptops from digit.in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db656733",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.digit.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a30e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaming_laptop=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div/div/div/article/div/div/div/div[2]/div/div[1]/div[3]/div[1]/div[6]/div[1]/div[1]/a')\n",
    "gaming_laptop.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230153b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "\n",
    "name_tag=driver.find_elements(By.XPATH,'//h3[@class=\"font130 mt0 mb10 mobilesblockdisplay \"]')\n",
    "for tag in name_tag:\n",
    "    name.append(tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d37e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "OS=[]\n",
    "\n",
    "os_tag=driver.find_elements(By.XPATH,'//span[@class=\"meta_v_value\"]')\n",
    "for tag in os_tag:\n",
    "    result=tag.text\n",
    "    OS.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcd3280",
   "metadata": {},
   "outputs": [],
   "source": [
    "Operating_System=OS[::3]\n",
    "Display_size=OS[1::3]\n",
    "Processor=OS[2::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51404eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_url=[]\n",
    "\n",
    "url_tag=driver.find_elements(By.XPATH,'//h3[@class=\"font130 mt0 mb10 mobilesblockdisplay \"]//a')\n",
    "for url in url_tag:\n",
    "    product_url.append(url.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5815046",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(name),len(Operating_System),len(Display_size),len(Processor),len(product_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe2bb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Laptop=pd.DataFrame({'Name':name,'Operating_system':Operating_System,'Display_size':Display_size,'Processor':Processor,'Product_URL':product_url})\n",
    "Laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec612d0",
   "metadata": {},
   "source": [
    "# 7. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped:“Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0f5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('http://www.forbes.com/')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838acbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "billionaires=driver.find_element(By.XPATH,'/html/body/div[1]/header/nav/div[1]/div[1]/div/div[2]/ul/li[2]/div[2]/div[3]/ul/li[1]/a')\n",
    "billionaires.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1741ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "name=[]\n",
    "net_worth=[]\n",
    "Age=[]\n",
    "Citizenship=[]\n",
    "source=[]\n",
    "Industries=[]\n",
    "\n",
    "\n",
    "rank_tag=driver.find_elements(By.XPATH,'//div[@class=\"TableRow_row__L-0Km\"]/div[1]/div')\n",
    "try:\n",
    "    for tag in rank_tag:\n",
    "        Rank.append(tag.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('_')\n",
    "\n",
    "name_tag=driver.find_elements(By.XPATH,'//div[@class=\"TableRow_row__L-0Km\"]/div[2]')\n",
    "try:\n",
    "     for tag in name_tag:\n",
    "        name.append(tag.text)\n",
    "except NoSuchElementException:\n",
    "        name.append('_')\n",
    "\n",
    "net_worthtag=driver.find_elements(By.XPATH,'//div[@class=\"TableRow_row__L-0Km\"]/div[3]')\n",
    "try:\n",
    "    for tag in net_worthtag:\n",
    "        net_worth.append(tag.text)\n",
    "except NoSuchElementException: \n",
    "    net_worth.append('_')\n",
    "\n",
    "\n",
    "age_tag=driver.find_elements(By.XPATH,'//div[@class=\"TableRow_row__L-0Km\"]/div[4]')\n",
    "try:\n",
    "    for tag in age_tag:\n",
    "        Age.append(tag.text)\n",
    "except NoSuchElementException:\n",
    "    Age.append('_')\n",
    "    citizenship_tag=driver.find_elements(By.XPATH,'//div[@class=\"TableRow_row__L-0Km\"]/div[5]')\n",
    "try:\n",
    "    for tag in citizenship_tag:\n",
    "        Citizenship.append(tag.text)\n",
    "except NoSuchElementException:\n",
    "    Citizenship.append('_')\n",
    "    \n",
    "source_tag=driver.find_elements(By.XPATH,'//div[@class=\"Table_dataCell__2QCve\"]/span')\n",
    "for tag in source_tag:\n",
    "    source.append(tag.text)\n",
    "    \n",
    "industry_tag=driver.find_elements(By.XPATH,'//div[@class=\"TableRow_row__L-0Km\"]/div[7]/div')\n",
    "try:\n",
    "    for tag in industry_tag:\n",
    "        Industries.append(tag.text)\n",
    "except NoSuchElementException:\n",
    "    Industries.append('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477a784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Rank),len(name),len(net_worth),len(Age),len(Citizenship),len(source),len(Industries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c82e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Billionaires=pd.DataFrame({'Rank':Rank,'Name':name,'Net Worth':net_worth,'Age':Age,'Citizenship':Citizenship,'Source':source,'Industry':Industries})\n",
    "Billionaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca92ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted\n",
    "from any YouTube Video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c2d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.youtube.com/watch?v=rmeGVhhbGrM')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c830740",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(40):\n",
    "    driver.execute_script(\"window.scrollBy(0,500)\")\n",
    "    \n",
    "Comment=[]\n",
    "i=0\n",
    "\n",
    "comment_tag=driver.find_elements(By.XPATH,'//yt-formatted-string[@class=\"style-scope ytd-comment-renderer\"]')\n",
    "for tag in comment_tag:\n",
    "    if i>=500:\n",
    "        break\n",
    "    Comment.append(tag.text)\n",
    "    i+=1\n",
    "    \n",
    "timing=[]\n",
    "i=0\n",
    "\n",
    "time_tag=driver.find_elements(By.XPATH,'//a[@class=\"yt-simple-endpoint style-scope yt-formatted-string\"]')\n",
    "for tag in time_tag:\n",
    "    if i>=500:\n",
    "        break\n",
    "    timing.append(tag.text)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3614297",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Comment),len(timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31c2ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Comments=pd.DataFrame({'Comment':Comment,'Time':timing})\n",
    "Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ba4b0",
   "metadata": {},
   "source": [
    "# 9. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overallreviews, privates from price, dorms from price, facilities and property description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8830f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.hostelworld.com/')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6388d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[3]/div/div/div[2]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[2]/input')\n",
    "search.send_keys('London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5872aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,'/html/body/div[3]/div/div/div[2]/div[2]/div[2]/div/div/div/div[5]/button[2]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14259cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import ElementNotInteractableException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ef3bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS=[]\n",
    "start=0\n",
    "end=4\n",
    "\n",
    "for page in range (start,end):\n",
    "    url_tag=driver.find_elements(By.XPATH,'//a[@data-v-774cba8c]')\n",
    "    for tag in url_tag:     \n",
    "        URLS.append(tag.get_attribute('href'))\n",
    "try:\n",
    "    next_button=driver.find_element(By.XPATH,'//button[@data-v-6686d382][2]') \n",
    "    next_button.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print('Exception raised:',e)\n",
    "    next_button1=driver.fint_element(By.XPATH,'/html/body/div[3]/div/div/div[2]/div[2]/div[1]/div/div/div[7]/div/button[2]')\n",
    "    next_button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835ed9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(URLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1dc539",
   "metadata": {},
   "outputs": [],
   "source": [
    "Names=[]\n",
    "Facilities=[]\n",
    "Description=[]\n",
    "Ratings=[]\n",
    "Total_reviews=[]\n",
    "Overallreviews=[]\n",
    "Distance=[]\n",
    "privateprices=[]\n",
    "dormsprices=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6cd295",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in URLS:\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "\n",
    "    try:\n",
    "        name_tag=driver.find_elements(By.XPATH,'//h1[@class=\"name title-4-bld\"]')\n",
    "        Names.append(name_tag[0].text if name_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "        Names.append('_')\n",
    "        \n",
    "    try:\n",
    "        facility_tag=driver.find_elements(By.XPATH,'//ul[@class=\"facilities\"]/li[2]/span')\n",
    "        Facilities.append(facility_tag[0].text if facility_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "         Facilities.append('_')\n",
    "            try:\n",
    "        description_tag=driver.find_elements(By.XPATH,'//p[@class=\"text line-clamp\"]')\n",
    "        Description.append(description_tag[0].text if description_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "        Description.append('_')\n",
    "        \n",
    "\n",
    "    try:\n",
    "        rating_tag=driver.find_elements(By.XPATH,'//div[@class=\"rating-container collapsed\"]/div[1]/div[1]/div[1]/span[1]')\n",
    "        Ratings.append(rating_tag[0].text if rating_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "        Ratings.append('_')\n",
    "        \n",
    "    try:\n",
    "        totalreview_tag=driver.find_elements(By.XPATH,'//div[@class=\"rating-container collapsed\"]/div[1]/div[1]/div[2]/span')\n",
    "        Total_reviews.append(totalreview_tag[0].text if totalreview_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "        Total_reviews.append('_')\n",
    "        \n",
    "    try:\n",
    "        overallreview_tag=driver.find_elements(By.XPATH,'//div[@class=\"rating-container collapsed\"]/div[1]/div[1]/div[1]/span[2]')\n",
    "        Overallreviews.append(overallreview_tag[0].text if overallreview_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "        Overallreviews.append('_')\n",
    "          try:\n",
    "        privateprice_tag=driver.find_elements(By.XPATH,'//div[@data-v-c8d46c14]/div/div[2]/div[2]/div[3]/div[1]/div[3]')\n",
    "        privateprices.append(privateprice_tag[0].text if privateprice_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "        privateprices.append('_')\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        dormsprice_tag=driver.find_elements(By.XPATH,'//div[@data-v-c8d46c14]/div[2]/div[1]/div[2]/div[3]/div[1]/div[3]')\n",
    "        dormsprices.append(dormsprice_tag[0].text if dormsprice_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "        dormsprices.append('_')\n",
    "    \n",
    "    try:\n",
    "        distance_tag=driver.find_elements(By.XPATH,'//li[@class=\"city-center\"]')\n",
    "        for tag in distance_tag:    \n",
    "            Distance.append(tag.text)\n",
    "    except NoSuchElementException:\n",
    "        Distance.append('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34cdfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Distances=[i.split()[0] for i in Distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4123e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Names),len(Facilities),len(Description),len(Ratings),len(Total_reviews),len(Overallreviews),len(privateprices),len(dormsprices),len(Distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe10a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hostel=pd.DataFrame({'Hostel name':Names,'Distance from CityCentre(KM)':Distances,'Ratings':Ratings,'Total Reviews':Total_reviews,'Overall Reviews':Overallreviews,'Privates from Price':privateprices,'Dorms from price':dormsprices,'Facilities':Facilities,'Property Description':Description})\n",
    "Hostel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df0448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04e9a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1473d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
